{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution3D, MaxPooling3D, Convolution2D, AveragePooling2D, MaxPooling2D, ZeroPadding3D, ZeroPadding2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import cv2\n",
    "import operator\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import keras\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Models\n",
    "from models_keras import CNNT4, CNNT5, VGG_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = 'D1'  # or 'D2'\n",
    "\n",
    "train_non = pd.read_csv('/data/train_data_0_{}.csv'.format(dataset_config))\n",
    "val_non = pd.read_csv('/data/val_data_0_{}.csv'.format(dataset_config))\n",
    "train_nod = pd.read_csv('/data/train_data_1.csv')\n",
    "val_nod = pd.read_csv('/data/val_data_1.csv')\n",
    "\n",
    "candidates_train = pd.concat([train_non, train_nod])\n",
    "candidates_val = pd.concat([val_non, val_nod])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1646349e30444b408c50c5f05511ca24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f15b0373cda46d0be34e48769503598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load 2-D DATA\n",
    "\n",
    "X_train, Y_train = [], []\n",
    "X_test, Y_test = [], []\n",
    "train_mean, val_mean = [], []\n",
    "\n",
    "train_names, val_names = [], []\n",
    "\n",
    "for row in tqdm(candidates_train.iterrows()):\n",
    "    image = row[1]\n",
    "    y_class = int(image['class'])\n",
    "    lung_img = np.load(image['filename'])\n",
    "    if lung_img.shape[0] == 32:\n",
    "        X = lung_img[16, :, :].reshape((32, 32))\n",
    "        train_mean.append(np.mean(X))\n",
    "        if np.mean(X) > 1:\n",
    "            X_train.append(X.reshape((32, 32, 1))), Y_train.append(y_class)\n",
    "            train_names.append(image['filename'])\n",
    "            \n",
    "for row in tqdm(candidates_val.iterrows()):\n",
    "    image = row[1]\n",
    "    y_class = int(image['class'])\n",
    "    lung_img = np.load(image['filename'])\n",
    "    if lung_img.shape[0] == 32:\n",
    "        X = lung_img[16, :, :].reshape((32, 32))\n",
    "        val_mean.append(np.mean(X))\n",
    "        if np.mean(X) > 1:\n",
    "            X_test.append(X.reshape((32, 32, 1))), Y_test.append(y_class)\n",
    "            val_names.append(image['filename'])\n",
    "\n",
    "\n",
    "X_train, Y_train = np.array(X_train), np.array(Y_train)\n",
    "X_test, Y_test = np.array(X_test), np.array(Y_test)\n",
    "\n",
    "Y_train = np_utils.to_categorical(Y_train, 2)\n",
    "Y_test = np_utils.to_categorical(Y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30436, 32, 32, 1), (30436, 2), (16705, 32, 32, 1), (16705, 2), 30436, 16705)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape, len(train_names), len(val_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58.531994, 59.46621, 58.556988, 59.63016)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some statistics on data\n",
    "np.mean(X_train), np.std(X_train), np.mean(X_test), np.std(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range changing\n",
    "# [-1, 1]\n",
    "# X_train_range = X_train*np.std(X_train)+np.mean(X_train)\n",
    "# X_test_range = X_test*np.std(X_test)+np.mean(X_test)\n",
    "# [0, 1]\n",
    "X_train_range = (X_train-np.mean(X_train))/np.std(X_train)\n",
    "X_test_range = (X_test-np.mean(X_test))/np.std(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30436 samples, validate on 16705 samples\n",
      "Epoch 1/30\n",
      "30436/30436 [==============================] - 4s 138us/step - loss: 0.6077 - acc: 0.6815 - val_loss: 0.5565 - val_acc: 0.7243\n",
      "Epoch 2/30\n",
      "30436/30436 [==============================] - 2s 53us/step - loss: 0.5352 - acc: 0.7428 - val_loss: 0.5159 - val_acc: 0.7465\n",
      "Epoch 3/30\n",
      "30436/30436 [==============================] - 2s 52us/step - loss: 0.4975 - acc: 0.7673 - val_loss: 0.4871 - val_acc: 0.7682\n",
      "Epoch 4/30\n",
      "30436/30436 [==============================] - 2s 51us/step - loss: 0.4645 - acc: 0.7872 - val_loss: 0.4561 - val_acc: 0.7873\n",
      "Epoch 5/30\n",
      "30436/30436 [==============================] - 2s 51us/step - loss: 0.4382 - acc: 0.8040 - val_loss: 0.4384 - val_acc: 0.7952\n",
      "Epoch 6/30\n",
      "30436/30436 [==============================] - 2s 50us/step - loss: 0.4132 - acc: 0.8182 - val_loss: 0.4161 - val_acc: 0.8102\n",
      "Epoch 7/30\n",
      "30436/30436 [==============================] - 2s 50us/step - loss: 0.3957 - acc: 0.8268 - val_loss: 0.4238 - val_acc: 0.8093\n",
      "Epoch 8/30\n",
      "30436/30436 [==============================] - 2s 53us/step - loss: 0.3813 - acc: 0.8353 - val_loss: 0.3976 - val_acc: 0.8235\n",
      "Epoch 9/30\n",
      "30436/30436 [==============================] - 2s 54us/step - loss: 0.3690 - acc: 0.8394 - val_loss: 0.4091 - val_acc: 0.8181\n",
      "Epoch 10/30\n",
      "30436/30436 [==============================] - 2s 53us/step - loss: 0.3580 - acc: 0.8472 - val_loss: 0.3956 - val_acc: 0.8276\n",
      "Epoch 11/30\n",
      "30436/30436 [==============================] - 2s 52us/step - loss: 0.3463 - acc: 0.8552 - val_loss: 0.3970 - val_acc: 0.8289\n",
      "Epoch 12/30\n",
      "30436/30436 [==============================] - 2s 53us/step - loss: 0.3359 - acc: 0.8599 - val_loss: 0.3773 - val_acc: 0.8368\n",
      "Epoch 13/30\n",
      "30436/30436 [==============================] - 2s 50us/step - loss: 0.3274 - acc: 0.8646 - val_loss: 0.3686 - val_acc: 0.8411\n",
      "Epoch 14/30\n",
      "30436/30436 [==============================] - 2s 52us/step - loss: 0.3215 - acc: 0.8653 - val_loss: 0.3602 - val_acc: 0.8441\n",
      "Epoch 15/30\n",
      "30436/30436 [==============================] - 2s 51us/step - loss: 0.3124 - acc: 0.8690 - val_loss: 0.3570 - val_acc: 0.8478\n",
      "Epoch 16/30\n",
      "30436/30436 [==============================] - 2s 51us/step - loss: 0.3069 - acc: 0.8711 - val_loss: 0.3676 - val_acc: 0.8424\n",
      "Epoch 17/30\n",
      "30436/30436 [==============================] - 1s 49us/step - loss: 0.3001 - acc: 0.8766 - val_loss: 0.3704 - val_acc: 0.8439\n",
      "Epoch 18/30\n",
      "30436/30436 [==============================] - 2s 51us/step - loss: 0.2947 - acc: 0.8782 - val_loss: 0.3549 - val_acc: 0.8509\n",
      "Epoch 19/30\n",
      "30436/30436 [==============================] - 2s 52us/step - loss: 0.2866 - acc: 0.8820 - val_loss: 0.3737 - val_acc: 0.8451\n",
      "Epoch 20/30\n",
      "30436/30436 [==============================] - 2s 51us/step - loss: 0.2797 - acc: 0.8854 - val_loss: 0.3802 - val_acc: 0.8449\n",
      "Epoch 21/30\n",
      "30436/30436 [==============================] - 2s 53us/step - loss: 0.2742 - acc: 0.8864 - val_loss: 0.3490 - val_acc: 0.8549\n",
      "Epoch 22/30\n",
      "30436/30436 [==============================] - 2s 53us/step - loss: 0.2696 - acc: 0.8914 - val_loss: 0.3725 - val_acc: 0.8478\n",
      "Epoch 23/30\n",
      "30436/30436 [==============================] - 2s 52us/step - loss: 0.2637 - acc: 0.8916 - val_loss: 0.3507 - val_acc: 0.8551\n",
      "Epoch 24/30\n",
      "30436/30436 [==============================] - 2s 53us/step - loss: 0.2584 - acc: 0.8944 - val_loss: 0.3494 - val_acc: 0.8575\n",
      "Epoch 25/30\n",
      "30436/30436 [==============================] - 2s 52us/step - loss: 0.2532 - acc: 0.8970 - val_loss: 0.3608 - val_acc: 0.8550\n",
      "Epoch 26/30\n",
      "30436/30436 [==============================] - 2s 53us/step - loss: 0.2499 - acc: 0.8995 - val_loss: 0.3500 - val_acc: 0.8596\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 27/30\n",
      "30436/30436 [==============================] - 2s 50us/step - loss: 0.2361 - acc: 0.9048 - val_loss: 0.3536 - val_acc: 0.8590\n",
      "Epoch 28/30\n",
      "30436/30436 [==============================] - 2s 51us/step - loss: 0.2348 - acc: 0.9059 - val_loss: 0.3493 - val_acc: 0.8603\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.rmsprop(lr=0.0001, rho=0.95)\n",
    "# opt = keras.optimizers.adam(lr=0.0001)\n",
    "model = CNNT4() \n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "callback = [EarlyStopping(monitor='val_loss', patience=7),\n",
    "            ReduceLROnPlateau(patience=5, verbose=1)]\n",
    "\n",
    "\n",
    "history = model.fit(x=X_train_range, y=Y_train, epochs=30, validation_data=(X_test_range, Y_test),\n",
    "          batch_size=128, callbacks=callback) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['acc', 'val_loss', 'loss', 'val_acc', 'lr'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logs = pd.DataFrame(columns=['val_acc', 'val_loss', 'train_loss', 'train_acc'])\n",
    "df_logs['val_acc'] =history.history['val_acc']\n",
    "df_logs['val_loss'] = history.history['val_loss']\n",
    "df_logs['train_acc'] = history.history['acc']\n",
    "df_logs['train_loss'] = history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logs.to_csv('/logs/models/cnnt4_{}.csv'.format(dataset_config), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGS = '/SubmitModels/'\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(LOGS+\"cnnt4_{}.json\".format(dataset_config), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5 \n",
    "model.save_weights(LOGS + 'cnnt4_{}.h5'.format(dataset_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
